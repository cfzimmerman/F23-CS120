**Interval scheduling as a reduction**

- Setup:
  - Input: Collection of intervals, _[a_0, b_0], ..., [a_{n - 1}, b*{n - 1}], a <= b*
  - Output: YES if intervals are all disjoint (for all indices i and j, [a, b] at i does not intersect [a, b] at j)
- Solution:
  - Sort intervals by start time
  - For each entry, check if the end of the current entry intersects with the beginning of the next entry
- Interval scheduling problem reduces to sorting
  - Ignoring time required to sort is O(n) (iterating intervals)
- Corollarys from reduction:
  - If sorting requires `n log n` time, interval scheduling decition has `n log n` time complexity
  - If all start times are in some universe of size U, [U], use counting sort and the algorithm solving the scheduling problem
- Key idea: to get multiple solutions to a problem, create a reduction. That reduction gives us many solutions to the problem.

**Lemma**

- Let _pi_ and _gamma_ be complex problems where _pi_ (interval scheduling) reduces to _gamma_ (sorting)
  - If there exists an algorithm solving gamma, there exists an algorithm solving pi
  - If there does not exist any algorithm solving pi, then there does not exist any algorithm solving gamma
  - If there exists an algorithm solving gamma with runtime g(n) and pi <= gamma, then there exists an algorithm for pi of runtime _O(T(n) + g(f(n)))_

**Repeated scheduling**

- Given a new interval [a_n, b_n], can we do better than run the original algorithm again
- We could reuse the initial sorting
- Given some interval in the middle, we could run binary search to see if some existing entry intersects

**Static data structures**

- Our initial definition of an algorithm doesn't really accomodate this solution for repeated scheduling
- Setup: "Given our sorted collection of intervals, we want to be able to tell people whether or not that time is booked" (no mutations)
  - Input is now a quadruple: _PI = (I, O, Q, f)_
  - For a static data structure problem, an implementation is now a pair of algorithms, _(preprocess, evaluate)_

**Static predecessor problems**

- Input: array of key-value pairs (k_i, v_i)
- Queries:
  - Search(k): output some key, value pair for which the key matches (k_i, v_i) where k_i = k
  - Next_smaller(k): output some key, value pair for which that key is the greatest of the input keys less than i.
- _Q = {("search", k in Reals)} U {("next_smaller", k in Reals)}_

**Implementation of static predecessors**

- Preprocess([k_0, v_0], ..., [k_n, v_n]): sort in O(n log n) to get a sorted array
- Eval(x', [search, k]): use binary search
- Eval(x', [next_smaller, k]): use modified binary search (because there may be many entries of the same key)
  - If the key we're requesting the next smallest for is actually the first key, then we return bot, no valid answer
- Key idea for implementation is that the first binary search might yield a key in the middle of many duplicate keys, so the initial binary search isn't enough

**Dynamic data structures**

- Input is now a quintuple: (Inputs, Outputs, U valid answers, Q queries, f)
- For every sequence of updates, u*0, u_1, ..., u*{m - 1}, f(x, q, u_0, u_1, ...) is now a subset of O
  - With a data structure that can handle updates, inputs isn't quite as important, we can build what we need from updates

**Dynamic data structure problem**

- Defined with (I, O, U, Q, f):
- Implementation is 3 algorithms (preprocess, eval, [update?])
- See lecture notes for the rest
